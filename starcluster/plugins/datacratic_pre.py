from starcluster import clustersetup
from starcluster.logger import log


class DatacraticPrePlugin(clustersetup.DefaultClusterSetup):

    def __init__(self, tag_billcode, security_groups=[]):
        self.tag_billcode = tag_billcode
        if type(security_groups) is list:
            self.security_groups = security_groups
        else:
            self.security_groups = \
                [sg.strip() for sg in security_groups.split(",")]

    def run(self, nodes, master, user, user_shell, volumes):
        master.add_tag("billcode", self.tag_billcode)
        self.update_security_groups(master)

    def on_add_node(self, node, nodes, master, user, user_shell, volumes):

        node.add_tag("billcode", self.tag_billcode)
        self.update_security_groups(node)

        #create a 20GB swap in a background process
        log.info("Creating 20GB swap space on node " + node.alias)
        msg = node.ssh.execute("file /mnt/20GB.swap", ignore_exit_status=True)
        if msg[0].find("ERROR") != -1:
            node.ssh.execute_async(
                'echo "(/bin/dd if=/dev/zero of=/mnt/20GB.swap bs=1M '
                'count=20480; '
                '/sbin/mkswap /mnt/20GB.swap; '
                '/sbin/swapon /mnt/20GB.swap;) &" > createSwap.sh; '
                'bash createSwap.sh; rm createSwap.sh')

        # Run the /home/useradd.sh script if it exists
        # that script is generated by saltstack and contains
        # the commands used to setup users on the worker nodes
        node.ssh.execute("test -f /home/useradd.sh && /home/useradd.sh")

        log.info("Creating /mnt/s3cache")
        msg = node.ssh.execute("file /mnt/s3cache", ignore_exit_status=True)
        if msg[0].find("ERROR") == -1:
                log.warning("/mnt/s3Cache already exists")
        else:
                node.ssh.execute("install -d -m 1777 /mnt/s3cache")

    def on_remove_node(self, node, nodes, master, user, user_shell, volumes):
        pass

    def clean_cluster(self, nodes, master, user, user_shell, volumes):
        pass

    def recover(self, nodes, master, user, user_shell, volumes):
        pass

    def update_security_groups(self, node):
        groups = [str(g.id) for g in node.instance.groups] \
            + self.security_groups
        log.info("Updating {} security groups to {}" \
                 .format(node.short_alias, groups))
        rez = node.ec2.conn.modify_instance_attribute(node.instance.id,
                                                      "groupSet",
                                                      groups)
        if not rez:
            log.error("Failed to assign additional security groups to {}"
                      .format(node.short_alias))
